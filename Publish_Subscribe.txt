Based on the Availability :


import serial
import paho.mqtt.client as mqtt
import time

# MQTT Broker and Sensor Topic
broker_address = "10.0.52.169"
sensor_topic = "sensor/data"

# Define MQTT Client
client = mqtt.Client("SensorPublisher")

# Connect to the MQTT Broker
client.connect(broker_address)

# Initialize the serial connection to Arduino
ser = serial.Serial('/dev/ttyACM0', 9600)

while True:
    try:
        # Read sensor data from Arduino
        read_serial = ser.readline().decode('utf-8').strip()

        # Publish the data to the MQTT broker
        client.publish(sensor_topic, read_serial)

        print("Published data: ", read_serial)

    except Exception as err:
        print("Error: {}".format(err.args))

    # Add a delay to control the publishing rate
    time.sleep(5)  # Adjust the delay as needed







To subscribe


import paho.mqtt.client as mqtt

# MQTT Broker and Sensor Topic
broker_address = "10.0.52.169"
sensor_topic = "sensor_data"

# Callback when the client connects to the MQTT broker
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        # print("Connected to MQTT Broker")
        client.subscribe(sensor_topic)
    else:
        print("Connection failed")

# Callback when a message is received from the MQTT broker
def on_message(client, userdata, message):
    print(f"Received message on topic {message.topic}: {message.payload.decode('utf-8')}")

# Define MQTT Client
client = mqtt.Client("SensorSubscriber")

# Set callback functions
client.on_connect = on_connect
client.on_message = on_message

# Connect to the MQTT Broker
client.connect(broker_address)

# Start the MQTT client loop to listen for messages
client.loop_forever()





























import cv2

# Load the pre-trained face detection model
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# Load the pre-trained face recognition model
face_recognizer = cv2.face.LBPHFaceRecognizer_create()
face_recognizer.read('face_recognition_model.xml')

# Capture video from your camera (camera index 0)
cap = cv2.VideoCapture(0)

# Define the known person's ID (you need to train your model to recognize this person)
known_person_id = 1

while True:
    ret, frame = cap.read()

    # Convert the frame to grayscale for face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces in the frame
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)

    for (x, y, w, h) in faces:
        # Perform face recognition on each detected face
        roi_gray = gray[y:y + h, x:x + w]
        person_id, _ = face_recognizer.predict(roi_gray)

        # Check if the recognized person matches the known person
        if person_id == known_person_id:
            print("Matched")
            # You can add further actions here if a match is found
        else:
            print("Not Matched")

        # Draw a rectangle around the detected face
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the frame with detected faces
    cv2.imshow('Face Recognition', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()













